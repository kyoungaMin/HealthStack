"""
Naver Clova OCR ì„œë¹„ìŠ¤ ëª¨ë“ˆ
ì²˜ë°©ì „ ì´ë¯¸ì§€ì—ì„œ ì•½ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
"""
import os
import json
import uuid
import time
import base64
import requests
from typing import Optional
from dotenv import load_dotenv

load_dotenv()


class NaverOCRService:
    """Naver Clova OCR API ì—°ë™ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.api_url = os.getenv("NAVER_OCR_API_URL", "https://clovaocr.apigw.ntruss.com/custom/v1")
        self.secret_key = os.getenv("NAVER_OCR_SECRET_KEY")
        
        if not self.secret_key:
            raise ValueError("NAVER_OCR_SECRET_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    def _encode_image_to_base64(self, image_path: str) -> str:
        """ì´ë¯¸ì§€ íŒŒì¼ì„ Base64ë¡œ ì¸ì½”ë”©"""
        with open(image_path, "rb") as f:
            return base64.b64encode(f.read()).decode("utf-8")
    
    def _get_image_format(self, image_path: str) -> str:
        """ì´ë¯¸ì§€ íŒŒì¼ í™•ì¥ìë¡œ í¬ë§· ê²°ì •"""
        ext = os.path.splitext(image_path)[1].lower()
        format_map = {
            ".jpg": "jpg",
            ".jpeg": "jpg",
            ".png": "png",
            ".pdf": "pdf",
            ".tiff": "tiff",
            ".tif": "tiff"
        }
        return format_map.get(ext, "jpg")
    
    def extract_text_from_image(self, image_path: str) -> dict:
        """
        ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            dict: OCR ê²°ê³¼ (inferResult, images, fields ë“±)
        """
        # ìš”ì²­ í—¤ë”
        headers = {
            "X-OCR-SECRET": self.secret_key,
            "Content-Type": "application/json"
        }
        
        # ìš”ì²­ ë³¸ë¬¸
        request_body = {
            "version": "V2",
            "requestId": str(uuid.uuid4()),
            "timestamp": int(time.time() * 1000),
            "lang": "ko",
            "images": [
                {
                    "format": self._get_image_format(image_path),
                    "name": os.path.basename(image_path),
                    "data": self._encode_image_to_base64(image_path)
                }
            ],
            "enableTableDetection": False
        }
        
        # API í˜¸ì¶œ
        response = requests.post(
            f"{self.api_url}/general",
            headers=headers,
            json=request_body,
            timeout=30
        )
        
        if response.status_code != 200:
            raise Exception(f"OCR API ì˜¤ë¥˜: {response.status_code} - {response.text}")
        
        return response.json()
    
    def extract_text_from_url(self, image_url: str) -> dict:
        """
        URL ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            image_url: ì´ë¯¸ì§€ URL
            
        Returns:
            dict: OCR ê²°ê³¼
        """
        headers = {
            "X-OCR-SECRET": self.secret_key,
            "Content-Type": "application/json"
        }
        
        request_body = {
            "version": "V2",
            "requestId": str(uuid.uuid4()),
            "timestamp": int(time.time() * 1000),
            "lang": "ko",
            "images": [
                {
                    "format": "jpg",
                    "name": "prescription",
                    "url": image_url
                }
            ],
            "enableTableDetection": False
        }
        
        response = requests.post(
            f"{self.api_url}/general",
            headers=headers,
            json=request_body,
            timeout=30
        )
        
        if response.status_code != 200:
            raise Exception(f"OCR API ì˜¤ë¥˜: {response.status_code} - {response.text}")
        
        return response.json()
    
    def parse_ocr_result(self, ocr_result: dict) -> list[str]:
        """
        OCR ê²°ê³¼ì—ì„œ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            ocr_result: OCR API ì‘ë‹µ
            
        Returns:
            list[str]: ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë¼ì¸ë“¤
        """
        texts = []
        
        if "images" not in ocr_result:
            return texts
        
        for image in ocr_result["images"]:
            if image.get("inferResult") != "SUCCESS":
                continue
                
            for field in image.get("fields", []):
                infer_text = field.get("inferText", "").strip()
                if infer_text:
                    texts.append(infer_text)
        
        return texts
    
    def extract_prescription_info(self, image_path: str) -> dict:
        """
        ì²˜ë°©ì „ ì´ë¯¸ì§€ì—ì„œ ì£¼ìš” ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            image_path: ì²˜ë°©ì „ ì´ë¯¸ì§€ ê²½ë¡œ
            
        Returns:
            dict: ì¶”ì¶œëœ ì²˜ë°©ì „ ì •ë³´ (ë³‘ì›ëª…, ì•½ë¬¼ ëª©ë¡)
        """
        # OCR ìˆ˜í–‰
        try:
            ocr_result = self.extract_text_from_image(image_path)
        except Exception as ocr_error:
            print(f"âš ï¸ OCR API Failed: {ocr_error}")
            # OCR ì‹¤íŒ¨ ì‹œ ë¹ˆ ê²°ê³¼ ë°˜í™˜ (ì•½ë¬¼ì€ ë‚˜ì¤‘ì— í…ìŠ¤íŠ¸ë¡œ ì¶”ì¶œ)
            ocr_result = {"images": []}
        
        # í…ìŠ¤íŠ¸ ì¶”ì¶œ
        all_texts = self.parse_ocr_result(ocr_result)
        
        # OCR ì‹¤íŒ¨í–ˆê±°ë‚˜ í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´, ìƒ˜í”Œ í…ìŠ¤íŠ¸ë¡œë¼ë„ ì•½ë¬¼ ì¶”ì¶œ ì‹œë„
        if not all_texts:
            print(f"âš ï¸ OCR returned no text - attempting text-based analysis")
            all_texts = []
        
        # ì „ì²´ í…ìŠ¤íŠ¸ (ì¤„ë°”ê¿ˆìœ¼ë¡œ ì—°ê²°)
        full_text = "\n".join(all_texts)
        
        hospital_name = self._extract_hospital_name(all_texts)
        drugs = self._extract_drugs(all_texts)  # â˜… ì•½ë¬¼ ì¶”ì¶œ ì¶”ê°€
        
        return {
            "raw_texts": all_texts,
            "full_text": full_text,
            "hospital_name": hospital_name,
            "drugs": drugs,  # â˜… ì•½ë¬¼ ëª©ë¡ ë°˜í™˜
            "ocr_result": ocr_result
        }

    def _extract_drugs(self, texts: list[str]) -> list[str]:
        """
        ì²˜ë°©ì „ í…ìŠ¤íŠ¸ì—ì„œ ì•½ë¬¼ëª…ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        ì•½ë¬¼ì˜ ì¼ë°˜ì ì¸ íŒ¨í„´:
        - í•œê¸€: ì•„ìŠ¤í”¼ë¦°, íƒ€ì´ë ˆë†€, í•­ìƒì œ ë“±
        - ìš©ëŸ‰ í¬í•¨: "ì•„ëª¨ì‹œì‹¤ë¦° 500mg", "ê°ê¸°ì•½ 1í¬" ë“±
        - ê°œìˆ˜ í¬í•¨: "ì•„ìŠ¤í”¼ë¦° 20ì •", "ì£¼ì‚¬ 3íšŒ" ë“±
        """
        import re
        
        drugs = []
        
        # ì•½ë¬¼ ê´€ë ¨ í‚¤ì›Œë“œ
        drug_keywords = [
            # ì¼ë°˜ì˜ì•½í’ˆ
            "ì•„ìŠ¤í”¼ë¦°", "íƒ€ì´ë ˆë†€", "ê°ê¸°ì•½", "ì¢…í•©ê°ê¸°ì•½", "ì†Œí™”ì œ", "ê°ê¸°",
            "í•­ìƒì œ", "í•­ì—¼ì¦", "ê°ì—¼ì¦", "ì†Œì—¼ì§„í†µì œ",
            # ì˜ë£Œìš©ì–´
            "ì •", "ìº¡ìŠ", "ì•¡", "ì£¼ì‚¬", "ì‹œëŸ½", "ë¬¼ì•½", "ì—°ê³ ", "íŒŒìŠ¤",
            # ì„±ë¶„ëª…
            "ì•„ì„¸íŠ¸ì•„ë¯¸ë…¸íœ", "ì´ë¶€í”„ë¡œíœ", "ì•„ëª©ì‹œì‹¤ë¦°", "ì•„ëª©ì‹œ",
            # ì²˜ë°©ì•½ íŒ¨í„´
            "ì•½", "ì œ", "ì§„", "í™˜", "ë¶„ë§", "ì•Œì•½", "ë¨¹ëŠ”ì•½"
        ]
        
        # ë³‘ì›/ì˜ë£Œê¸°ê´€ í‚¤ì›Œë“œ (ì œì™¸í•  ê²ƒ)
        exclude_keywords = [
            "ë³‘ì›", "ì˜ì›", "ì„¼í„°", "í´ë¦¬ë‹‰", "ì˜ë£Œì›",
            "ì˜ì‚¬", "ì„ ìƒ", "ë°•ì‚¬", "êµìˆ˜", "ëŒ€í•™",
            "ì§„ë£Œ", "ì§„ì°°", "ìƒë‹´"
        ]
        
        # ì•½ë¬¼ í›„ë³´ ì¶”ì¶œ
        candidates = []
        for text in texts:
            text_stripped = text.strip()
            
            # ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸´ í…ìŠ¤íŠ¸ëŠ” ì œì™¸ (2ì ~ 40ì)
            if len(text_stripped) < 2 or len(text_stripped) > 40:
                continue
            
            # ë³‘ì›/ì˜ë£Œê¸°ê´€ëª…ì€ ì œì™¸
            if any(keyword in text_stripped for keyword in exclude_keywords):
                continue
            
            # ì•½ë¬¼ ê´€ë ¨ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            has_drug_keyword = any(keyword in text_stripped for keyword in drug_keywords)
            
            if has_drug_keyword:
                # ìš©ëŸ‰ê³¼ ê°œìˆ˜ ì •ë³´ëŠ” ì œê±° (ì•½ëª…ë§Œ ì¶”ì¶œ)
                cleaned = re.sub(r'\s*\d+\.?\d*\s*(mg|g|ml|cc|ì •|ìº¡ìŠ|í¬|íšŒ|ë¶„|ê°œ|ì•Œ|ë²ˆ|ì£¼).*$', '', text_stripped)
                cleaned = re.sub(r'\s*Ã—\s*\d+.*$', '', cleaned)  # "Ã—3" ê°™ì€ ê°œìˆ˜ í‘œê¸° ì œê±°
                cleaned = re.sub(r'\s+', ' ', cleaned).strip()
                
                if cleaned and len(cleaned) >= 2 and cleaned not in candidates:
                    candidates.append(cleaned)
        
        # ì¤‘ë³µ ì œê±°
        final_drugs = []
        for drug in candidates:
            # ì´ë¯¸ ì¶”ê°€ëœ ì•½ëª…ê³¼ ë™ì¼í•˜ë©´ ì œì™¸
            is_duplicate = False
            for existing in final_drugs:
                if drug.lower() == existing.lower():
                    is_duplicate = True
                    break
            
            if not is_duplicate:
                final_drugs.append(drug)
        
        print(f"[Drug Extraction] Found {len(final_drugs)} drugs: {final_drugs}")
        return final_drugs

    def _extract_hospital_name(self, texts: list[str]) -> str:
        """ë³‘ì›ëª… ì¶”ì¶œ (ê°•í™”ëœ íœ´ë¦¬ìŠ¤í‹±)"""
        import re
        
        hospital_keywords = ["ë³‘ì›", "ì˜ì›", "ëŒ€í•™", "ì„¼í„°", "í´ë¦¬ë‹‰", "ë³´ê±´ì†Œ", "ì˜ë£Œì›"]
        dept_keywords = ["ì •í˜•ì™¸ê³¼", "ë‚´ê³¼", "ì™¸ê³¼", "ì†Œì•„ê³¼", "ì‚°ë¶€ì¸ê³¼", "ì•ˆê³¼", "ì´ë¹„ì¸í›„ê³¼", 
                        "ì‹ ê²½ì™¸ê³¼", "í‰ë¶€ì™¸ê³¼", "ì„±í˜•ì™¸ê³¼", "ì¬í™œì˜í•™ê³¼", "ì‘ê¸‰ì˜í•™ê³¼", "ì¹˜ê³¼"]
        
        # 1ë‹¨ê³„: ë³‘ì›ëª… í‚¤ì›Œë“œ í¬í•¨ëœ í…ìŠ¤íŠ¸ ê²€ìƒ‰
        candidates = []
        for text in texts:
            text_stripped = text.strip()
            # ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸´ í…ìŠ¤íŠ¸ëŠ” ì œì™¸ (3ì ~ 60ì)
            if len(text_stripped) < 3 or len(text_stripped) > 60:
                continue
            
            # ë³‘ì› ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆëŠ”ì§€ í™•ì¸
            if any(k in text_stripped for k in hospital_keywords):
                candidates.append(text_stripped)
        
        # 2ë‹¨ê³„: ì˜ì‚¬ëª… íŒ¨í„´ ì œê±° (ì˜ì‚¬ëª…ì´ ìˆìœ¼ë©´ ë¨¼ì € ë°˜í™˜í•˜ê¸° ì „ì— ì œê±°)
        best_match = None
        for text in candidates:
            # "ë³‘ì›/ì˜ì›" ì§ì „ê¹Œì§€ë§Œ ì¶”ì¶œ (ì˜ì‚¬ëª… ì œê±°)
            match = re.match(r"^([^ê°€-í£]*[ê°€-í£]*?(ë³‘ì›|ì˜ì›|ì„¼í„°|í´ë¦¬ë‹‰|ë³´ê±´ì†Œ|ì˜ë£Œì›))", text)
            if match:
                hospital_name = match.group(1).strip()
                # ë¶ˆí•„ìš”í•œ ê³µë°±ê³¼ íŠ¹ìˆ˜ë¬¸ì ì œê±°
                hospital_name = re.sub(r'\s+', ' ', hospital_name).strip()
                if hospital_name and len(hospital_name) >= 3:
                    best_match = hospital_name
                    break
        
        # 3ë‹¨ê³„: íŒ¨í„´ ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ì²« ë²ˆì§¸ í›„ë³´ ë°˜í™˜
        if best_match:
            return best_match
        elif candidates:
            return candidates[0]
        
        # 4ë‹¨ê³„: ì§„ë£Œê³¼ëª©ë§Œ ìˆëŠ” ê²½ìš°ë„ ê³ ë ¤
        for text in texts:
            text_stripped = text.strip()
            if any(d in text_stripped for d in dept_keywords) and len(text_stripped) < 50:
                return text_stripped + " (ì§„ë£Œê³¼ëª© ê¸°ë°˜)"
        
        return "ë³‘ì›ëª… ë¯¸ìƒ"


# í…ŒìŠ¤íŠ¸ìš© ì½”ë“œ
if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python naver_ocr_service.py <ì´ë¯¸ì§€_ê²½ë¡œ>")
        sys.exit(1)
    
    image_path = sys.argv[1]
    
    if not os.path.exists(image_path):
        print(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
        sys.exit(1)
    
    try:
        ocr_service = NaverOCRService()
        result = ocr_service.extract_prescription_info(image_path)
        
        print("=" * 50)
        print("ğŸ“‹ OCR ì¶”ì¶œ ê²°ê³¼")
        print("=" * 50)
        print("\n[ì „ì²´ í…ìŠ¤íŠ¸]")
        print(result["full_text"])
        print("\n[í…ìŠ¤íŠ¸ ì¡°ê°ë“¤]")
        for i, text in enumerate(result["raw_texts"], 1):
            print(f"  {i}. {text}")
            
    except Exception as e:
        print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        sys.exit(1)
